# Code Quality

Quality philosophy, tooling, and enforcement for the collector service. For pipeline-wide quality standards, see the [system Code Quality page](https://github.com/couchcryptid/storm-data-system/wiki/Code-Quality).

## Coding Philosophy

### Type safety as a guardrail

TypeScript strict mode catches an entire class of bugs at compile time. Zod validates configuration at startup, ensuring runtime values match expected shapes before any processing begins. The type system is a collaborator, not an obstacle.

### Structured, composable modules

Each concern has a clear home: CSV parsing (`csv/`), Kafka publishing (`kafka/`), scheduling (`scheduler/`), health and metrics (`health/`, `metrics.ts`). Modules export narrow interfaces and accept dependencies via constructor parameters.

### Fail fast on bad configuration

Configuration is validated with Zod at startup. Missing or invalid environment variables cause an immediate exit with a descriptive error -- not a cryptic runtime failure minutes later.

### Batch-oriented processing

CSV rows are accumulated into batches before publishing to Kafka. This amortizes network overhead and aligns with Kafka's strength as a batch-friendly transport. Batch size and flush intervals are configurable.

### Structured logging

All log calls use Pino with structured context as the first argument. In development, `pino-pretty` provides human-readable output. In production, logs are emitted as JSON for machine parsing. Log levels are configurable via `LOG_LEVEL`.

### Cron schedule matches data cadence

NOAA publishes daily CSV files. The collector fetches on a matching schedule (configurable cron expression) rather than polling in real time. It also runs once immediately on startup for fast feedback during development.

## Static Analysis

### ESLint + TypeScript

ESLint flat config with `@typescript-eslint` provides type-aware linting. Key checks:

| Category | What It Catches |
|----------|----------------|
| Type safety | `@typescript-eslint/recommended-type-checked` rules |
| Unused code | Unused variables, imports, parameters |
| Style | Consistent patterns via ESLint recommended rules |
| Formatting | Prettier integration (no conflicts between linter and formatter) |

TypeScript compiler (`tsc --noEmit`) runs as a separate CI step to verify full type safety.

### Prettier

All TypeScript files are formatted with Prettier. Configuration enforced via:
- Pre-commit hook (`prettier --write` on staged files)
- CI lint job (`npm run lint`)

### SonarQube Cloud

Analyzed via CI on every push and pull request: [SonarCloud dashboard](https://sonarcloud.io/summary/overall?id=couchcryptid_storm-data-collector)

SonarCloud configuration (`sonar-project.properties`):
- Reports TypeScript coverage via `coverage/lcov.info` (generated by `@vitest/coverage-v8`)

## Security

| Layer | What It Catches |
|-------|----------------|
| TypeScript strict mode | Null/undefined access, type mismatches |
| `@typescript-eslint` | Type-aware pattern detection |
| Zod config validation | Malformed configuration at startup |
| SonarCloud hotspots | Framework-specific security patterns |

## Quality Gates

### Pre-commit Hooks

Husky + lint-staged runs on every commit:

1. `prettier --write` on staged TypeScript files
2. `eslint --fix` on staged TypeScript files
3. Full unit test suite (`npm run test:unit`)

Integration tests are excluded from pre-commit (too slow). Run them manually before PRs with `npm run test:integration`.

### CI Pipeline

Every push and pull request to `main` runs:

| Job | Command | What It Enforces |
|-----|---------|-----------------|
| `test-unit` | `npm run test:unit` | Unit tests |
| `lint` | `npm run lint` + `npm run typecheck` | ESLint + TypeScript strict mode |
| `build` | `npm run build` | Compile check |
| `sonarcloud` | SonarCloud scan | Coverage, bugs, vulnerabilities, code smells, security hotspots |

### SonarCloud Quality Gate

Uses the default "Sonar way" gate on new code: >= 80% coverage, <= 3% duplication, A ratings for reliability/security/maintainability, 100% security hotspots reviewed.

## Testing

Tests are organized in two tiers. See [[Development]] for commands.

| Tier | What It Covers | Docker |
|------|---------------|--------|
| Unit | CSV parsing, scheduling, Kafka publishing, metrics (mocked dependencies) | No |
| Integration | Full CSV-to-Kafka pipeline with real Kafka (testcontainers) | Yes |

Unit tests use Vitest with `@vitest/coverage-v8` for coverage reporting (V8-native coverage, not Istanbul).

## Related

- [System Code Quality](https://github.com/couchcryptid/storm-data-system/wiki/Code-Quality) -- pipeline-wide quality standards
- [[Development]] -- commands, CI pipeline, logging, metrics
- [[Architecture]] -- service design, module layout
